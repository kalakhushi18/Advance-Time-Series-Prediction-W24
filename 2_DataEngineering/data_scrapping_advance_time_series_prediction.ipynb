{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series Analysis Project\n",
    "\n",
    "This project is part of the *Advanced Time Series Prediction* course at OpenCampus, Kiel University. The primary goal is to conduct a comprehensive *multivariate time series analysis* to forecast the daily closing price of Bitcoin, focusing on the influence of various economic, social, and sentiment-based factors. \n",
    "\n",
    "### Project Objective\n",
    "\n",
    "We aim to predict **Bitcoin’s daily closing prices** by examining the potential impact of multiple time series variables:\n",
    "- **S&P 500 Closing Data**: to capture broad market movements.\n",
    "- **Inflation Rate**: to account for macroeconomic pressures.\n",
    "- **Daily Treasury Rates**: representing economic stability indicators.\n",
    "- **Bitcoin Daily Google Trends**: to gauge public interest.\n",
    "- **Twitter Sentiments**: to assess social media sentiment around Bitcoin.\n",
    "- **Holiday Indicator**: to consider public holidays and weekends as factors that might influence trading volume and price volatility.\n",
    "\n",
    "### Data Processing and Pretreatment\n",
    "\n",
    "The collected data will undergo a series of pretreatment steps, including:\n",
    "- **Typecasting** to ensure compatibility between time series values.\n",
    "- **Handling Missing Values** using appropriate imputation techniques to maintain data integrity.\n",
    "\n",
    "### Goal\n",
    "\n",
    "The ultimate goal is to utilize this preprocessed dataset in a predictive model that accurately captures the relationship between Bitcoin’s closing prices and the identified factors, achieving reliable forecasts for strategic decision-making. This project provides hands-on experience in multivariate time series forecasting and enhances practical knowledge in handling complex datasets, developing critical skills for time series modeling and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rate\n",
    "### Code Explanation\n",
    "\n",
    "In the following script, we are downloading daily U.S. Treasury rates data for each year from 01-11-2014 up to today. Our goal is to extract only the *Date* column and the first data column immediately after that is **4-week Bank Discount** rate. We then save the resulting dataset as a `.csv` file.\n",
    "\n",
    "Here’s a step-by-step breakdown of what this code does:\n",
    "\n",
    "1. **Imports**:  \n",
    "   - We import the essential libraries: `requests` to make HTTP requests, `pandas` for data manipulation, `io` to handle in-memory text data, and `datetime` to get the current year dynamically.\n",
    "\n",
    "2. **Data Retrieval and Processing**:  \n",
    "   - We start by initializing an empty DataFrame named `daily_treasury_rates` to store data across multiple years.\n",
    "   - We define the structure of the URL with `base_url`, which we’ll use to download each year’s data.\n",
    "   - Using `datetime.now().year`, we determine the current year and create a range from 2014 to this year. This ensures that we retrieve the most current data available\n",
    "   - For each year in this range, we format the URL, request the data, and read it into a DataFrame if the response is successful (`status code 200`).\n",
    "   - We only select the *Date* column and the first data column next to it (`.iloc[:, :2]`), keeping the dataset focused on key information only.\n",
    "   - Each year’s selected data is appended to `daily_treasury_rates` with `pd.concat()`.\n",
    "\n",
    "3. **Saving the Data**:  \n",
    "   - Finally, we saved (in local directory) our combined data as a `.csv` file, excluding row indices thanks to `index=False`.\n",
    "\n",
    "### Why We Focus on the **4-Week Bank Discount Rate**\n",
    "\n",
    "We’re interested in the **4-week Bank Discount** rate because it’s crucial for studying the multivariate time series relationship between U.S. interest rates and **Bitcoin** prices. This short-term rate offers insights into borrowing costs and liquidity in the economy, influencing investor preferences and risk appetite. These factors can significantly affect asset prices, including cryptocurrencies. By focusing on this daily rate, we capture high-frequency movements in interest rates, which could correlate with Bitcoin’s price dynamics. This approach may reveal important relationships or patterns within the market structure over time, helping us understand how interest rate changes might influence cryptocurrency prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 rows added for year 2014\n",
      "251 rows added for year 2015\n",
      "250 rows added for year 2016\n",
      "250 rows added for year 2017\n",
      "249 rows added for year 2018\n",
      "250 rows added for year 2019\n",
      "251 rows added for year 2020\n",
      "251 rows added for year 2021\n",
      "249 rows added for year 2022\n",
      "250 rows added for year 2023\n",
      "211 rows added for year 2024\n",
      "Data has been saved to daily_treasury_rates.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import requests  # For sending HTTP requests\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import io  # For handling in-memory text data as files\n",
    "from datetime import datetime  # For getting the current year\n",
    "\n",
    "# Initialize an empty DataFrame to store the daily treasury rates data\n",
    "daily_treasury_rates = pd.DataFrame()\n",
    "\n",
    "# Define the base URL format and the range of years for data retrieval\n",
    "base_url = \"https://home.treasury.gov/resource-center/data-chart-center/interest-rates/daily-treasury-rates.csv/{year}/all?type=daily_treasury_bill_rates&field_tdr_date_value={year}&page&_format=csv\"\n",
    "current_year = datetime.now().year  # Get the current year\n",
    "years = range(2014, current_year + 1)  # Set the range of years from 2014 to the current year\n",
    "\n",
    "# Loop through each year, download the CSV data, and append only the required columns to the main DataFrame\n",
    "for year in years:\n",
    "    # Format the URL for the current year\n",
    "    url = base_url.format(year=year)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200 indicates success)\n",
    "    if response.status_code == 200:\n",
    "        # Read the CSV data for the current year from the response\n",
    "        yearly_data = pd.read_csv(io.StringIO(response.text))\n",
    "        \n",
    "        # Select only the \"Date\" column and the column immediately after it\n",
    "        selected_data = yearly_data.iloc[:, :2]\n",
    "        \n",
    "        # Append selected data to the main DataFrame and print the number of rows added\n",
    "        daily_treasury_rates = pd.concat([daily_treasury_rates, selected_data], ignore_index=True)\n",
    "        print(f\"{len(selected_data)} rows added for year {year}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for year {year}\")\n",
    "\n",
    "# Save the daily treasury rates data to a CSV file on the D: drive\n",
    "daily_treasury_rates.to_csv(\"daily_treasury_rates.csv\", index=False)\n",
    "print(\"Data has been saved to daily_treasury_rates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation Expectation\n",
    "### Code Explanation\n",
    "\n",
    "This Python script is designed to download daily inflation data represented by the **T10YIE** (10-Year Breakeven Inflation Rate) from the `Federal Reserve Economic Data (FRED)` website. Here’s a breakdown of what the code does:\n",
    "\n",
    "1. **Imports**:  \n",
    "   - The script begins by importing the necessary libraries: `requests` to handle HTTP requests and `datetime` to manage date and time data.\n",
    "\n",
    "2. **Data Retrieval and Processing**:  \n",
    "   - We define the start date as **November 1, 2014**, and the end date is set to today’s date, dynamically determined using `datetime.today().strftime(\"%Y-%m-%d\")`. This ensures that we always fetch the most recent data available.\n",
    "\n",
    "   - The URL is constructed using the defined date range to request the **T10YIE** data in CSV format. This data represents the market's expectations of future inflation based on the yield difference between nominal and inflation-protected securities.\n",
    "\n",
    "   - A GET request is sent to the FRED URL to retrieve the data. The script checks if the request is successful (HTTP status code **200**). \n",
    "\n",
    "3. **Saving the Data**:  \n",
    "   - If the data retrieval is successful, the script saves the content to a CSV file named `inflation_data.csv` in the current working directory. If the request fails, it prints an error message with the status code.\n",
    "\n",
    "### Importance of Using the **10-Year Breakeven Inflation Expectation** Rate\n",
    "\n",
    "Using the **daily T10YIE rate** as a proxy for inflation data is crucial because the **Consumer Price Index (CPI)** is not available on a daily basis. The T10YIE provides a timely measure of inflation expectations that can be correlated with Bitcoin prices. \n",
    "\n",
    "By analyzing the multivariate time series relationship between daily T10YIE rates and Bitcoin prices, we can gain insights into how market perceptions of inflation impact cryptocurrency valuations. This approach allows us to capture rapid changes in inflation expectations, providing a more nuanced understanding of the interactions between traditional financial metrics and emerging digital asset prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully downloaded and saved to inflation_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests  # For sending HTTP requests\n",
    "from datetime import datetime  # For handling date and time\n",
    "\n",
    "# Define the date range for the data\n",
    "start_date = \"2014-11-01\"  # Starting date for the data\n",
    "end_date = datetime.today().strftime(\"%Y-%m-%d\")  # Today's date as the ending date\n",
    "\n",
    "# Construct the URL for downloading data from FRED\n",
    "url = f\"https://fred.stlouisfed.org/graph/fredgraph.csv?id=T10YIE&cosd={start_date}&coed={end_date}&fq=Daily\"\n",
    "\n",
    "# Request the data from FRED\n",
    "response = requests.get(url)  # Send a GET request to the specified URL\n",
    "\n",
    "# Check if the request was successful (status code 200 indicates success)\n",
    "if response.status_code == 200:\n",
    "    # Define the path to save the CSV file in the current directory\n",
    "    file_path = \"inflation_data.csv\"  # Save in the local directory (current working directory)\n",
    "    \n",
    "    # Save the content to a CSV file\n",
    "    with open(file_path, 'wb') as file:  # Open the file in write-binary mode\n",
    "        file.write(response.content)  # Write the response content to the file\n",
    "    \n",
    "    print(f\"Data successfully downloaded and saved to {file_path}\")  # Success message\n",
    "else:\n",
    "    print(f\"Failed to download data. Status code: {response.status_code}\")  # Error message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Market Index (S&P 500)\n",
    "### Code Explanation\n",
    "\n",
    "In this Python script, we aim to download historical daily closing prices for the **S&P 500** index using the **Yahoo Finance** API. Below is a breakdown of what our code accomplishes:\n",
    "\n",
    "1. **Imports**:  \n",
    "   - We start by importing the necessary libraries: `yfinance` for fetching financial data from Yahoo Finance and `pandas` for data manipulation and analysis.\n",
    "\n",
    "2. **Ticker Symbol Definition**:  \n",
    "   - We define the ticker symbol for the S&P 500 as `^GSPC`, which we will use to fetch the index data.\n",
    "\n",
    "3. **Date Range Setup**:  \n",
    "   - Our script sets the start date to **November 1, 2014**, and the end date is dynamically set to today's date using `pd.Timestamp.today().strftime('%Y-%m-%d')`. This ensures that we retrieve the most current data available.\n",
    "\n",
    "4. **Data Retrieval**:  \n",
    "   - Using `yf.download()`, we fetch the historical data for the specified ticker symbol over the defined date range.\n",
    "\n",
    "5. **Data Extraction**:  \n",
    "   - We extract only the closing prices from the downloaded data, focusing on the `Close` column.\n",
    "\n",
    "6. **Data Saving**:  \n",
    "   - Finally, we save the closing prices to a CSV file named `sp500_closing_data.csv` in our local directory.\n",
    "\n",
    "### Importance of Using Daily Closing S&P 500 Data\n",
    "\n",
    "Utilizing the **daily closing index of the S&P 500** is vital for us when studying the multivariate time series relationship between the **U.S. stock index** and **Bitcoin** prices. The S&P 500 serves as a key indicator of the overall health of the U.S. economy and investor sentiment. By analyzing the daily fluctuations in the S&P 500 alongside Bitcoin prices, we can identify potential correlations and trends.\n",
    "\n",
    "The daily closing data provides us with a granular view of market dynamics, allowing us to detect patterns that may influence Bitcoin valuations. As both the stock market and cryptocurrency market can react to macroeconomic news and investor sentiment, understanding their relationship can help us develop investment strategies and risk management practices. This analysis ultimately leads us to a deeper understanding of how traditional financial metrics and digital assets interact in the broader financial landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of S&P 500 closing data:\n",
      "                  Close\n",
      "Date                   \n",
      "2014-11-03  2017.810059\n",
      "2014-11-04  2012.099976\n",
      "2014-11-05  2023.569946\n",
      "2014-11-06  2031.209961\n",
      "2014-11-07  2031.920044\n",
      "Total days of data successfully scraped: 3656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf  # For downloading financial data from Yahoo Finance\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "\n",
    "# Define the ticker symbol for the S&P 500\n",
    "ticker_symbol = '^GSPC'  # Yahoo Finance ticker for the S&P 500\n",
    "\n",
    "# Set the start and end dates for the data retrieval\n",
    "start_date = '2014-11-01'  # Starting date for the historical data\n",
    "end_date = pd.Timestamp.today().strftime('%Y-%m-%d')  # Today's date as the ending date\n",
    "\n",
    "# Calculate the total number of days between start_date and end_date\n",
    "total_days = pd.date_range(start=start_date, end=end_date).shape[0]  # Total days in the date range\n",
    "\n",
    "# Fetch the historical data for the S&P 500\n",
    "sp500_data = yf.download(ticker_symbol, start=start_date, end=end_date)  # Download the data\n",
    "\n",
    "# Extract only the date and closing price from the data\n",
    "sp500_closing_data = sp500_data[['Close']]  # Focus on the 'Close' column\n",
    "\n",
    "# Save the closing data to a CSV file\n",
    "sp500_closing_data.to_csv('sp500_closing_data.csv')  # Write the DataFrame to a CSV file\n",
    "\n",
    "# Display the total number of days of data that were successfully scraped\n",
    "print(f\"Total days of data successfully scraped: {total_days}\")  # Print the total days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Trend - Interest over time\n",
    "### Code Explanation\n",
    "\n",
    "This Python script retrieves historical **Google Trends** data for the keyword \"bitcoin\" and stores it as daily interest data over multiple 3-month intervals. This allows us to analyze trends in Google searches related to Bitcoin. Below is a detailed breakdown of each section in the code:\n",
    "\n",
    "1. **Imports**:  \n",
    "   - We import `TrendReq` from `pytrends`, which allows us to interact with the Google Trends API.\n",
    "   - `pandas` is used for data manipulation, while `datetime` and `timedelta` help us work with date ranges.\n",
    "\n",
    "2. **Setting Up Pytrends**:  \n",
    "   - We initialize **Pytrends** with parameters such as `hl='en-US'` (language and region) and `tz=360` (timezone offset in minutes, where 360 equals UTC+6).\n",
    "\n",
    "3. **Defining Parameters**:  \n",
    "   - We specify \"bitcoin\" as the keyword to be searched and set a date range starting from **January 1, 2014** to the present date.\n",
    "\n",
    "4. **Looping Through 3-Month Intervals**:  \n",
    "   - Google Trends allows only a 90-day range for daily data. Therefore, we loop through each 3-month period from the start date to today’s date.\n",
    "   - For each interval, we set a **timeframe** and use `pytrends.build_payload` to fetch the data.\n",
    "   - The fetched data is then appended to an accumulating **DataFrame** (`all_data`).\n",
    "\n",
    "5. **Data Processing**:  \n",
    "   - We remove the `isPartial` column if it exists, as it only indicates incomplete data for the final days in a period.\n",
    "   - We reset the index of the DataFrame for a cleaner structure.\n",
    "\n",
    "6. **Saving Data**:  \n",
    "   - Finally, we save the combined dataset as a **CSV file** named `bitcoin_daily_google_trends.csv` in the local directory.\n",
    "\n",
    "### Importance of Using Google Trends Data\n",
    "\n",
    "Using **Google Trends** data, specifically the *interest over time* metric, is essential for studying the multivariate time series relationship between **Google search interest** and **Bitcoin prices**. The **daily interest scores** in Google Trends serve as a proxy for public interest, sentiment, or hype surrounding Bitcoin. \n",
    "\n",
    "Analyzing these trends allows us to identify whether there’s a correlation between spikes in search interest and Bitcoin's price movements. Google Trends data helps us gauge how shifts in public interest might influence Bitcoin's volatility and trading volume, providing valuable insights for both financial analysis and investment strategy development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hassanabsar\\anaconda3\\envs\\generic\\Lib\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pytrends.request import TrendReq  # For accessing Google Trends data\n",
    "import pandas as pd  # For data manipulation\n",
    "from datetime import datetime, timedelta  # For date handling\n",
    "\n",
    "# Initialize pytrends and set up parameters\n",
    "# 'hl' specifies the language (en-US for English, United States)\n",
    "# 'tz' specifies the timezone offset in minutes (360 for UTC+6)\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define the keyword to search for and the data range for the search\n",
    "keyword = \"bitcoin\"  # Keyword we are analyzing on Google Trends\n",
    "start_date = \"2014-11-01\"  # Start date for the data\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')  # Today's date as the end date\n",
    "\n",
    "# Initialize an empty DataFrame to store the accumulated results\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Convert start and end dates to datetime objects to support date arithmetic\n",
    "current_start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Loop through each 3-month interval to get daily trend data as Google Trends allows only up to 90 days for daily data granularity\n",
    "while current_start < end_date:\n",
    "    # Define the end of the current 3-month period or up to the end date\n",
    "    current_end = min(current_start + timedelta(days=90), end_date)\n",
    "    \n",
    "    # Format the time frame for Google Trends API\n",
    "    timeframe = f\"{current_start.strftime('%Y-%m-%d')} {current_end.strftime('%Y-%m-%d')}\"\n",
    "    \n",
    "    # Build the payload and retrieve interest over time data\n",
    "    # 'cat' is set to 0 (default), meaning no specific category filtering (or we can use cat=7 for finance)\n",
    "    # 'geo' is empty, so no country-specific filtering is applied (global data)\n",
    "    # 'gprop' is empty, meaning no specific Google property\n",
    "    pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo='', gprop='')\n",
    "    data = pytrends.interest_over_time()\n",
    "    \n",
    "    # Append the data for the current interval to the all_data DataFrame\n",
    "    if not data.empty:\n",
    "        all_data = pd.concat([all_data, data])\n",
    "\n",
    "    # Move the start date forward by one day after the current_end to avoid overlap\n",
    "    current_start = current_end + timedelta(days=1)\n",
    "\n",
    "# Remove the 'isPartial' column if it exists, as it indicates incomplete data\n",
    "if 'isPartial' in all_data.columns:\n",
    "    all_data = all_data.drop(columns=['isPartial'])\n",
    "\n",
    "# Reset the index for clean DataFrame formatting\n",
    "all_data.reset_index(inplace=True)\n",
    "\n",
    "# Save the combined data to a CSV file in the local directory\n",
    "all_data.to_csv('bitcoin_daily_google_trends.csv', index=False)  # Save without row index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin Historical Data\n",
    "\n",
    "### Code Explanation\n",
    "This Python script retrieves daily historical **closing prices** for **Bitcoin** (in USD) from **Yahoo Finance** and saves it to a CSV file. Below is a breakdown of each part of the code:\n",
    "\n",
    "1. **Define Ticker Symbol**:\n",
    "   - We specify the ticker symbol `BTC-USD`, which corresponds to **Bitcoin in USD** on Yahoo Finance.\n",
    "\n",
    "2. **Set the Date Range**:\n",
    "   - `start_date` is set to `'2014-11-01'`, the earliest available date for Bitcoin data.\n",
    "   - `end_date` is set to today’s date, ensuring that we retrieve the latest available data.\n",
    "\n",
    "3. **Fetch Historical Data**:\n",
    "   - We use `yf.download()` with the defined `ticker_symbol`, `start_date`, and `end_date` to download **historical Bitcoin data** for the specified date range.\n",
    "\n",
    "4. **Extract Closing Prices**:\n",
    "   - The data contains multiple columns (Open, High, Low, Close, etc.), but we are only interested in the **closing prices**. \n",
    "   - We extract the `Close` column and save it in a new DataFrame `btc_closing_data`.\n",
    "\n",
    "5. **Save Data to CSV**:\n",
    "   - We save the closing prices to a CSV file named **`bitcoin_closing_prices.csv`** in the local directory.\n",
    "\n",
    "This data provides daily Bitcoin closing prices over the specified period, which is useful for analyzing **Bitcoin's historical performance** and studying its relationship with other financial or economic indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total days of data retrieved: 3655\n",
      "Data starts from: 2014-11-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf  # For accessing financial data from Yahoo Finance\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "\n",
    "# Define the ticker symbol for Bitcoin\n",
    "ticker_symbol = 'BTC-USD'  # Yahoo Finance ticker for Bitcoin in USD\n",
    "\n",
    "# Set the start and end dates for the data retrieval\n",
    "start_date = '2014-11-01'  # Starting date for historical Bitcoin data\n",
    "end_date = pd.Timestamp.today().strftime('%Y-%m-%d')  # Today's date as the end date\n",
    "\n",
    "# Fetch the historical data for Bitcoin\n",
    "btc_data = yf.download(ticker_symbol, start=start_date, end=end_date)  # Download historical Bitcoin data\n",
    "\n",
    "# Check if we received data and display the first available date if we did\n",
    "if btc_data.empty:\n",
    "    print(\"No data retrieved for the specified date range. Bitcoin data may not be available before 2014.\")\n",
    "else:\n",
    "    # Extract only the closing prices from the data\n",
    "    btc_closing_data = btc_data[['Close']]  # Keep only the 'Close' column\n",
    "\n",
    "    # Calculate and display the total number of days of data retrieved\n",
    "    total_days = btc_closing_data.shape[0]  # Count the number of rows in the DataFrame\n",
    "    print(f\"\\nTotal days of data retrieved: {total_days}\")  # Display total days\n",
    "    print(f\"Data starts from: {btc_closing_data.index.min().date()}\")  # Display the earliest available date\n",
    "\n",
    "    # Save the closing prices to a CSV file in the local directory\n",
    "    btc_closing_data.to_csv('bitcoin_closing_prices.csv')  # Write the closing data to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created and saved as 'dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import holidays\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = datetime(2014, 11, 1)\n",
    "end_date = datetime.today()\n",
    "\n",
    "# Generate a date range for column 1\n",
    "dates = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Initialize the DataFrame with dates as the first column\n",
    "df = pd.DataFrame(dates, columns=['date'])\n",
    "\n",
    "# Load data from the specified CSV files\n",
    "btc_data = pd.read_csv('bitcoin_closing_prices.csv', index_col=0, parse_dates=True)\n",
    "sp500_data = pd.read_csv('sp500_closing_data.csv', index_col=0, parse_dates=True)\n",
    "inflation_data = pd.read_csv('inflation_data.csv', index_col=0, parse_dates=True)\n",
    "treasury_data = pd.read_csv('daily_treasury_rates.csv', index_col=0, parse_dates=True)\n",
    "google_trends_data = pd.read_csv('bitcoin_daily_google_trends.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Rename columns for uniformity\n",
    "btc_data.columns = ['bitcoin_closing_prices']\n",
    "sp500_data.columns = ['sp500_closing_data']\n",
    "inflation_data.columns = ['inflation_rate']\n",
    "treasury_data.columns = ['daily_treasury_rates']\n",
    "google_trends_data.columns = ['bitcoin_daily_google_trends']\n",
    "\n",
    "# Merge all the data on the 'date' column of the main DataFrame using left join\n",
    "df = df.merge(btc_data, how='left', left_on='date', right_index=True)\n",
    "df = df.merge(sp500_data, how='left', left_on='date', right_index=True)\n",
    "df = df.merge(inflation_data, how='left', left_on='date', right_index=True)\n",
    "df = df.merge(treasury_data, how='left', left_on='date', right_index=True)\n",
    "df = df.merge(google_trends_data, how='left', left_on='date', right_index=True)\n",
    "\n",
    "# Set up holiday dates\n",
    "us_holidays = holidays.US()  # U.S. holiday list\n",
    "\n",
    "# Add a column to mark holidays (both public holidays and weekends)\n",
    "df['is_holiday'] = df['date'].apply(\n",
    "    lambda x: 1 if x in us_holidays or x.weekday() >= 5 else 0  # Mark as holiday if it's a public holiday or weekend\n",
    ")\n",
    "\n",
    "# Create an empty 'twitter_sentiments_score' column\n",
    "df['twitter_sentiments_score'] = None\n",
    "\n",
    "# Save the final dataset to CSV\n",
    "df.to_csv('dataset.csv', index=False)\n",
    "\n",
    "print(\"Dataset created and saved as 'dataset.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
